import os
import json
import random
import re
import csv
import datetime
import time
from typing import Dict, Any, List, Tuple

from mpllm_prompts.prompts import gpt_trivia_prompt

# API è¨­å®š
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "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")
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
MODEL_NAME = os.environ.get("MODEL_NAME", "gpt-5-nano")  # å°ç…§çµ„ä½¿ç”¨ Mini

# OpenAI å®¢æˆ¶ç«¯è¨­å®š
try:
    from openai import OpenAI
    _use_openai_v1 = True
except Exception:
    _use_openai_v1 = False
    import openai


def build_openai_model_fn(model: str):
    """å»ºç«‹ OpenAI æ¨¡å‹å‡½æ•¸"""
    if _use_openai_v1:
        client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)

        def _model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=5000,
            )
            text = (resp.choices[0].message.content or "").strip()
            usage = getattr(resp, "usage", None)
            total_tokens = int(getattr(usage, "total_tokens", 0) if usage else 0)
            return text, total_tokens

        return _model_fn
    else:
        openai.api_key = OPENAI_API_KEY
        openai.api_base = OPENAI_BASE_URL

        def _model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
            resp = openai.ChatCompletion.create(model=model, messages=messages)
            text = (resp["choices"][0]["message"]["content"] or "").strip()
            usage = resp.get("usage") or {}
            total_tokens = int(usage.get("total_tokens") or 0)
            return text, total_tokens

        return _model_fn


def load_trivia_test_data():
    """è¼‰å…¥ trivia æ¸¬è©¦è³‡æ–™"""
    path = "./data/trivia_creative_writing/trivia_creative_writing_100_n_5.jsonl"
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f]


def create_trivia_prompt(questions: List[str], topic: str) -> str:
    """å‰µå»ºåˆä½µçš„ trivia promptï¼ˆå›ç­”å•é¡Œ + å¯«æ•…äº‹ï¼‰"""
    questions_str = "\n".join([f"{i+1}. {q}" for i, q in enumerate(questions)])
    prompt = gpt_trivia_prompt.replace("{topic}", topic).replace("{questions}", questions_str)
    return prompt


def run_trivia_phase(model_fn, questions: List[str], topic: str, verbose: bool = False) -> Tuple[List[str], str, int]:
    """åˆä½µéšæ®µ: ç›´æ¥å›ç­”å•é¡Œä¸¦æ’°å¯«æ•…äº‹
    
    Returns:
        (answers_list, story, tokens)
    """
    prompt = create_trivia_prompt(questions, topic)
    messages = [{"role": "user", "content": prompt}]
    
    result, tokens = model_fn(messages)
    
    # è§£æçµæœ
    answers_list = []
    story = ""
    
    try:
        # å˜—è©¦ç›´æ¥è§£æ JSON
        data = json.loads(result)
        answers_list = data.get("answers", [])
        story = data.get("story", "").strip()
    except json.JSONDecodeError:
        # å˜—è©¦ç”¨æ­£å‰‡è¡¨é”å¼æå– JSON
        m = re.search(r'\{[\s\S]*?"answers"[\s\S]*?"story"[\s\S]*?\}', result)
        if m:
            try:
                data = json.loads(m.group(0))
                answers_list = data.get("answers", [])
                story = data.get("story", "").strip()
            except json.JSONDecodeError:
                # åˆ†åˆ¥æå– answers å’Œ story
                # æå– answers
                answers_match = re.search(r'"answers"[\s\S]*?:[\s\S]*?\[([^\]]+)\]', result)
                if answers_match:
                    answers_list = [a.strip().strip('"\'') for a in answers_match.group(1).split(',')]
                
                # æå– story
                story_match = re.search(r'"story"[\s\S]*?:[\s\S]*?"([^"]+)"', result)
                if story_match:
                    story = story_match.group(1).strip()
    
    # ç¢ºä¿ç­”æ¡ˆæ•¸é‡æ­£ç¢º
    while len(answers_list) < len(questions):
        answers_list.append("unknown")
    answers_list = answers_list[:len(questions)]
    
    # æ¸…ç†æ•…äº‹ï¼ˆç§»é™¤å¯èƒ½çš„é›™å¼•è™Ÿï¼‰
    if story.startswith('"') and story.endswith('"'):
        story = story[1:-1]
    if story.startswith("'") and story.endswith("'"):
        story = story[1:-1]
    
    if verbose:
        print(f"  ç­”æ¡ˆ: {answers_list}")
        print(f"  æ•…äº‹: {story[:100]}...")
        print(f"  Token æ¶ˆè€—: {tokens}")
    
    return answers_list, story, tokens


# ===== æ¸¬è©¦å‡½æ•¸ =====
def normalize_answer(ans: str) -> str:
    """æ­£è¦åŒ–ç­”æ¡ˆ"""
    if not ans:
        return ""
    s = str(ans).lower().strip()
    s = re.sub(r"[^\w\s]", "", s)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    s = re.sub(r"\b(the|a|an|and|or|of|in|on|at|to|for|with|by)\b", " ", s)  # ç§»é™¤åœç”¨è©
    s = re.sub(r"\s+", " ", s).strip()  # æ­£è¦åŒ–ç©ºæ ¼
    return s


def test_single():
    """å–®é¡Œæ¸¬è©¦"""
    print("=== GPT-5 Mini å°ç…§çµ„æ¸¬è©¦ (å–®é¡Œ) ===")
    print("=" * 50)

    # è¼‰å…¥æ¸¬è©¦è³‡æ–™
    test_data = load_trivia_test_data()
    if not test_data:
        print("ç„¡æ³•è¼‰å…¥æ¸¬è©¦è³‡æ–™")
        return

    # éš¨æ©Ÿé¸ä¸€é¡Œæ¸¬è©¦
    item = random.choice(test_data)
    topic = item.get("topic", "General")
    questions = item.get("questions", [])
    correct_answers_list = item.get("answers", [])

    print(f"ä¸»é¡Œ: {topic}")
    print(f"å•é¡Œæ•¸: {len(questions)}")
    print()

    # è¨­å®šæ¨¡å‹
    model_fn = build_openai_model_fn(MODEL_NAME)

    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()

    # åˆä½µéšæ®µ: ç›´æ¥å›ç­”å•é¡Œä¸¦æ’°å¯«æ•…äº‹
    print("åŸ·è¡Œ: å›ç­”å•é¡Œä¸¦æ’°å¯«æ•…äº‹", end="", flush=True)
    answers_list, story, total_tokens = run_trivia_phase(model_fn, questions, topic, verbose=True)
    print(" âœ“\n")

    # è¨˜éŒ„çµæŸæ™‚é–“
    elapsed_time = time.time() - start_time

    # ç¸½çµ
    print("=" * 50)
    print(f"\nğŸ“Š Token çµ±è¨ˆ:")
    print(f"   ç¸½è¨ˆ: {total_tokens:,} tokens")
    print(f"\nâ±ï¸  åŸ·è¡Œæ™‚é–“: {elapsed_time:.2f}ç§’ ({elapsed_time/60:.2f}åˆ†é˜)")

    # ç­”æ¡ˆæ¯”å°
    correct_count = 0
    total_questions_count = len(questions)

    print(f"\nâœ… ç­”æ¡ˆæ¯”å°:")
    for i, final_ans in enumerate(answers_list):
        if i >= len(correct_answers_list):
            break

        final_norm = normalize_answer(final_ans)
        if not final_norm:
            status = "âŒ"
            print(f"   å•é¡Œ {i+1}: {status} | é æ¸¬: {final_ans[:30]:<30} | æ­£ç¢º: {', '.join(correct_answers_list[i][:2])}")
            continue

        # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ­£ç¢ºç­”æ¡ˆ
        matched = False
        for correct_ans in correct_answers_list[i]:
            correct_norm = normalize_answer(correct_ans)

            # ç²¾ç¢º/åŒ…å«åŒ¹é…
            if (
                final_norm == correct_norm
                or final_norm in correct_norm
                or correct_norm in final_norm
            ):
                correct_count += 1
                matched = True
                status = "âœ“"
                break

            # é—œéµè©åŒ¹é…ï¼ˆé•·åº¦>2çš„è©ï¼‰
            final_words = [w for w in final_norm.split() if len(w) > 2]
            correct_words = [w for w in correct_norm.split() if len(w) > 2]
            if any(w in correct_norm for w in final_words) or any(w in final_norm for w in correct_words):
                correct_count += 1
                matched = True
                status = "âœ“"
                break

        if not matched:
            status = "âœ—"

        print(f"   å•é¡Œ {i+1}: {status} | é æ¸¬: {final_ans[:30]:<30} | æ­£ç¢º: {', '.join(correct_answers_list[i][:2])}")

    # é¡¯ç¤ºæº–ç¢ºç‡
    accuracy = (correct_count / total_questions_count * 100) if total_questions_count > 0 else 0
    print(f"\nğŸ¯ æº–ç¢ºç‡: {correct_count}/{total_questions_count} ({accuracy:.1f}%)")

    # ä¿å­˜çµæœåˆ° CSV
    results_dir = "results"
    os.makedirs(results_dir, exist_ok=True)
    csv_path = os.path.join(results_dir, "results_gpt_trivia.csv")

    # ç¢ºä¿ CSV æœ‰æ¨™é ­
    header = ["æ™‚é–“", "ä¸»é¡Œ", "å•é¡Œæ•¸", "æ­£ç¢ºæ•¸", "æº–ç¢ºç‡", "ç¸½ Token", "åŸ·è¡Œæ™‚é–“(ç§’)", "æ¸¬è©¦æ¨¡å¼", "ç­”æ¡ˆ", "æ•…äº‹"]
    if not os.path.exists(csv_path):
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            csv.writer(f).writerow(header)
    else:
        try:
            with open(csv_path, 'r+', encoding='utf-8-sig') as f:
                first_line = f.readline()
                if not first_line or "æ™‚é–“" not in first_line:
                    content = f.read()
                    f.seek(0, 0)
                    f.write(",".join(header) + "\n" + content)
        except Exception:
            pass

    # ç²å–ç•¶å‰æ™‚é–“æˆ³
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # æº–å‚™è¼¸å‡ºå…§å®¹
    answers_json = json.dumps(answers_list, ensure_ascii=False, separators=(',', ':'))

    with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([
            timestamp, topic, len(questions), correct_count, f"{accuracy:.1f}%",
            total_tokens, f"{elapsed_time:.2f}", "single",
            answers_json, story
        ])

    print(f"\nğŸ“Š çµæœå·²å„²å­˜è‡³: {csv_path}")
    print("=" * 50)


def test_batch():
    """æ‰¹æ¬¡æ¸¬è©¦æ‰€æœ‰ 100 é¡Œ"""
    print("=== GPT-5 Mini å°ç…§çµ„æ¸¬è©¦ (æ‰¹æ¬¡ 100 é¡Œ) ===\n")

    # è®€å–é¡Œåº«
    data = load_trivia_test_data()
    total_groups = len(data)

    model_fn = build_openai_model_fn(MODEL_NAME)

    # çµ±è¨ˆè®Šæ•¸
    total_tokens = 0
    correct_count = 0
    total_questions = 0
    error_count = 0

    # æ™‚é–“çµ±è¨ˆ
    total_elapsed_time = 0.0

    # ç¢ºä¿ results è³‡æ–™å¤¾å­˜åœ¨
    results_dir = "results"
    os.makedirs(results_dir, exist_ok=True)

    # CSV æª”æ¡ˆè·¯å¾‘
    csv_path = os.path.join(results_dir, "results_gpt_trivia.csv")

    print(f"é–‹å§‹æ¸¬è©¦ {total_groups} çµ„...")
    print(f"çµæœå°‡è¨˜éŒ„è‡³: {csv_path}\n")

    # æª¢æŸ¥ä¸¦å¯«å…¥ CSV header
    header = ["æ™‚é–“", "ä¸»é¡Œ", "å•é¡Œæ•¸", "æ­£ç¢ºæ•¸", "æº–ç¢ºç‡", "ç¸½ Token", "åŸ·è¡Œæ™‚é–“(ç§’)", "æ¸¬è©¦æ¨¡å¼", "ç­”æ¡ˆ", "æ•…äº‹"]
    if not os.path.exists(csv_path):
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(header)
    else:
        try:
            with open(csv_path, 'r', encoding='utf-8-sig') as f:
                first_line = f.readline()
                if not first_line or "æ™‚é–“" not in first_line:
                    with open(csv_path, 'r+', encoding='utf-8-sig') as f2:
                        content = f2.read()
                        f2.seek(0, 0)
                        f2.write(",".join(header) + "\n" + content)
        except Exception:
            pass

    for idx, item in enumerate(data):
        topic = item.get("topic", "General")
        questions = item.get("questions", [])
        correct_answers_list = item.get("answers", [])

        # è¨ˆç®—å³æ™‚æº–ç¢ºåº¦
        current_accuracy = (correct_count / total_questions * 100) if total_questions > 0 else 0

        # é€²åº¦æ¢é¡¯ç¤º
        percent = (idx / total_groups)
        filled = int(30 * percent)
        bar = "=" * filled + "-" * (30 - filled)
        print(
            f"\ré€²åº¦: |{bar}| {idx}/{total_groups} ({percent*100:.1f}%) | æº–ç¢ºåº¦: {current_accuracy:.1f}% | {topic[:20]:<20}",
            end="",
            flush=True,
        )

        # è¨˜éŒ„ç”¨çš„è®Šæ•¸
        item_tokens = 0
        item_error = ""
        item_group_correct = 0
        item_error_occurred = False
        item_answers = []
        item_story = ""

        # è¨˜éŒ„å–®é¡Œé–‹å§‹æ™‚é–“
        item_start_time = time.time()

        try:
            # åˆä½µéšæ®µ: ç›´æ¥å›ç­”å•é¡Œä¸¦æ’°å¯«æ•…äº‹
            answers_list, story, item_tokens = run_trivia_phase(model_fn, questions, topic, verbose=False)
            total_tokens += item_tokens

            # è¨ˆç®—æº–ç¢ºåº¦
            group_correct = 0
            for i, final_ans in enumerate(answers_list):
                if i >= len(correct_answers_list):
                    break

                final_norm = normalize_answer(final_ans)
                if not final_norm:
                    continue

                # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ­£ç¢ºç­”æ¡ˆ
                matched = False
                for correct_ans in correct_answers_list[i]:
                    correct_norm = normalize_answer(correct_ans)

                    # ç²¾ç¢º/åŒ…å«åŒ¹é…
                    if (
                        final_norm == correct_norm
                        or final_norm in correct_norm
                        or correct_norm in final_norm
                    ):
                        group_correct += 1
                        matched = True
                        break

                    # é—œéµè©åŒ¹é…ï¼ˆé•·åº¦>2çš„è©ï¼‰
                    final_words = [w for w in final_norm.split() if len(w) > 2]
                    correct_words = [w for w in correct_norm.split() if len(w) > 2]
                    if any(w in correct_norm for w in final_words) or any(w in final_norm for w in correct_words):
                        group_correct += 1
                        matched = True
                        break

            item_group_correct = group_correct
            correct_count += group_correct
            total_questions += len(questions)

            # è¨˜éŒ„è¼¸å‡ºå…§å®¹
            item_answers = answers_list
            item_story = story

        except Exception as e:
            error_count += 1
            item_error_occurred = True
            item_error = str(e)
            import traceback
            if error_count <= 3:  # åªé¡¯ç¤ºå‰3å€‹éŒ¯èª¤
                traceback.print_exc()

        # è¨˜éŒ„å–®é¡ŒçµæŸæ™‚é–“
        item_elapsed_time = time.time() - item_start_time
        total_elapsed_time += item_elapsed_time

        # ç«‹å³å¯«å…¥æ¯ä¸€é¡Œçš„çµæœåˆ° CSV
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        item_accuracy = (item_group_correct / len(questions) * 100) if questions else 0

        # æº–å‚™è¼¸å‡ºå…§å®¹
        answers_json = json.dumps(item_answers, ensure_ascii=False, separators=(',', ':'))

        with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp, topic, len(questions), item_group_correct, f"{item_accuracy:.1f}%",
                item_tokens, f"{item_elapsed_time:.2f}", "batch",
                answers_json, item_story
            ])

    # å®Œæˆé€²åº¦æ¢
    bar = "=" * 30
    final_accuracy = (correct_count / total_questions * 100) if total_questions > 0 else 0
    print(f"\ré€²åº¦: |{bar}| {total_groups}/{total_groups} (100.0%) | æº–ç¢ºåº¦: {final_accuracy:.1f}% | å®Œæˆ!{' '*20}")

    # æœ€çµ‚çµ±è¨ˆ
    print(f"\n{'='*60}")
    print("æ¸¬è©¦å®Œæˆï¼")
    print(f"ç¸½é¡Œçµ„: {total_groups} | æˆåŠŸ: {total_groups - error_count} | éŒ¯èª¤: {error_count}")
    print(f"ç¸½å•é¡Œæ•¸: {total_questions}")
    print(f"æ­£ç¢ºç­”æ¡ˆ: {correct_count}")
    print(f"æº–ç¢ºåº¦: {final_accuracy:.1f}%")
    print(f"ç¸½ Token: {total_tokens:,} | å¹³å‡/çµ„: {total_tokens/total_groups:.0f}")

    # æ™‚é–“çµ±è¨ˆ
    avg_time_per_group = total_elapsed_time / total_groups if total_groups > 0 else 0
    print(f"ç¸½åŸ·è¡Œæ™‚é–“: {total_elapsed_time:.2f}ç§’ ({total_elapsed_time/60:.2f}åˆ†é˜)")
    print(f"å¹³å‡/çµ„: {avg_time_per_group:.2f}ç§’ ({avg_time_per_group/60:.2f}åˆ†é˜)")

    # æˆæœ¬ä¼°ç®—ï¼ˆGPT-5 Mini åƒ¹æ ¼ï¼‰
    input_ratio, output_ratio = 0.8, 0.2
    input_cost = total_tokens * input_ratio * 0.250 / 1_000_000
    output_cost = total_tokens * output_ratio * 2.000 / 1_000_000
    total_cost = input_cost + output_cost

    # å°å¹£æ›ç®— (1 USD = 30 TWD)
    total_cost_twd = total_cost * 30

    print(f"é ä¼°æˆæœ¬ (GPT-5 Mini):")
    print(f"   ç¸½è¨ˆ: ${total_cost:.6f} USD / NT${total_cost_twd:.2f}")
    print(f"å¹³å‡æˆæœ¬/çµ„: ${total_cost/total_groups:.6f} USD / NT${total_cost_twd/total_groups:.2f}")

    # å¯«å…¥æ‰¹æ¬¡æ¸¬è©¦ç¸½é«”çµ±è¨ˆåˆ° CSV
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([
            timestamp, f"æ‰¹æ¬¡æ¸¬è©¦({total_groups}çµ„)", total_questions, correct_count, f"{final_accuracy:.1f}%",
            total_tokens, f"{total_elapsed_time:.2f}", "batch_summary",
            "", ""  # æ‰¹æ¬¡ç¸½çµ±è¨ˆä¸åŒ…å«å€‹åˆ¥è¼¸å‡ºå…§å®¹
        ])

    print(f"\nğŸ“Š è©³ç´°çµæœå·²å„²å­˜è‡³: {csv_path}")
    print(f"{'='*60}")


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    print("è«‹é¸æ“‡æ¸¬è©¦æ¨¡å¼:")
    print("1. single - å–®é¡Œæ¸¬è©¦")
    print("2. batch - æ‰¹æ¬¡æ¸¬è©¦ï¼ˆ100é¡Œï¼‰\n")

    mode = input("è«‹è¼¸å…¥ 'single' æˆ– 'batch': ").strip().lower()

    if mode == "batch":
        test_batch()
    elif mode == "single":
        test_single()
    else:
        print("ç„¡æ•ˆé¸é …ï¼ŒåŸ·è¡Œå–®é¡Œæ¸¬è©¦...")
        test_single()


if __name__ == "__main__":
    main()

