import os
import json
import random
import re
import concurrent.futures
from typing import Dict, Any, List, Tuple

from mpllm_prompts.nano import nano_run, mini_mux
from mpllm_prompts.prompts import (
    trivia_researcher_prompt,
    trivia_thinker_prompt,
    trivia_decider_prompt,
    trivia_minimux_prompt,
)
from mpllm_prompts.switch_prompts import trivia_personas_switch_prompt

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "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")
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
MODEL_NAME = os.environ.get("MODEL_NAME", "gpt-5-nano")
MINI_MODEL_NAME = os.environ.get("MINI_MODEL_NAME", "gpt-5-mini")

try:
    from openai import OpenAI
    _use_openai_v1 = True
except Exception:
    _use_openai_v1 = False
    import openai


def build_openai_model_fn(model: str):
    """å»ºç«‹ OpenAI æ¨¡å‹å‡½æ•¸"""
    if _use_openai_v1:
        client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)

        def _model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
            resp = client.chat.completions.create(model=model, messages=messages)
            text = (resp.choices[0].message.content or "").strip()
            tokens = getattr(resp, "usage", None)
            total_tokens = getattr(tokens, "total_tokens", 0) if tokens else 0
            return text, int(total_tokens)

        return _model_fn
    else:
        openai.api_key = OPENAI_API_KEY
        openai.api_base = OPENAI_BASE_URL

        def _model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
            resp = openai.ChatCompletion.create(model=model, messages=messages)
            text = (resp["choices"][0]["message"]["content"] or "").strip()
            usage = resp.get("usage") or {}
            total_tokens = int(usage.get("total_tokens") or 0)
            return text, total_tokens

        return _model_fn


def load_trivia_test_data():
    """è¼‰å…¥ trivia æ¸¬è©¦è³‡æ–™"""
    path = "./data/trivia_creative_writing/trivia_creative_writing_100_n_5.jsonl"
    with open(path, 'r', encoding='utf-8') as f:
        return [json.loads(line) for line in f]


def run_trivia_multi_group_flow(
    model_fn, topic: str, questions: List[str], personas_data: Dict[str, Any], silent: bool = False
) -> Dict[str, Any]:
    """åŸ·è¡Œ Trivia å¤šç¾¤çµ„ä¸¦è¡Œæµç¨‹"""
    results: Dict[str, Any] = {}
    total_tokens = 0

    groups = personas_data.get("groups", [])
    
    if not silent:
        print(f"\nğŸ”¹ æ­¥é©Ÿ 2ï¼šåŸ·è¡Œå¤šç¾¤çµ„æµç¨‹ (å…± {len(groups)} çµ„)")
        print(f"   éšæ®µ 1ï¼šResearcher + Thinkers ä¸¦è¡Œ...", end="", flush=True)
    
    # æº–å‚™ prompts
    questions_json = json.dumps(questions, ensure_ascii=False, separators=(",", ":"))
    researcher_prompt = trivia_researcher_prompt \
        .replace("{n}", str(len(questions))) \
        .replace("{questions}", questions_json)
    
    thinker_prompts = []
    for group in groups:
        thinker_persona = group.get("thinker", "")
        thinker_prompt = trivia_thinker_prompt \
            .replace("{thinker_persona}", thinker_persona) \
            .replace("{topic}", topic)
        thinker_prompts.append(thinker_prompt)
    
    # ä¸¦è¡ŒåŸ·è¡Œ Researcher + Thinkers
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        researcher_future = executor.submit(nano_run, "", researcher_prompt, model_fn)
        thinker_futures = []
        for i, thinker_prompt in enumerate(thinker_prompts):
            future = executor.submit(nano_run, "", thinker_prompt, model_fn)
            thinker_futures.append((future, i+1))
        
        results_phase1 = {}
        for future in concurrent.futures.as_completed([researcher_future] + [f[0] for f in thinker_futures]):
            if future == researcher_future:
                try:
                    r_text, r_tokens, _ = future.result()
                    results_phase1['researcher'] = (r_text, r_tokens)
                except Exception as e:
                    results_phase1['researcher_error'] = str(e)
                    results_phase1['researcher'] = ("[]", 0)
            else:
                for thinker_future, group_id in thinker_futures:
                    if future == thinker_future:
                        try:
                            t_text, t_tokens, _ = future.result()
                            results_phase1[f'thinker_{group_id}'] = (t_text, t_tokens)
                        except Exception as e:
                            results_phase1[f'thinker_{group_id}_error'] = str(e)
                            results_phase1[f'thinker_{group_id}'] = ('{"creative_direction": "error"}', 0)
                        break
    
    # è™•ç† Researcher çµæœ
    r_text, r_tokens = results_phase1['researcher']
    m = re.search(r"\[[\s\S]*?\]", r_text)
    if m:
        r_text = m.group(0)
    else:
        r_text = "[]"
    
    answers = json.loads(r_text) if r_text else []
    total_tokens += r_tokens
    
    # è™•ç† Thinker çµæœ
    thinker_results = {}
    thinker_tokens_sum = 0
    for i, group in enumerate(groups):
        group_id = i + 1
        thinker_persona = group.get("thinker", "")
        t_text, t_tokens = results_phase1[f'thinker_{group_id}']
        
        # å¢å¼· JSON è§£æå®¹éŒ¯æ€§
        try:
            thinker_analysis = json.loads(t_text)
        except json.JSONDecodeError:
            # å˜—è©¦æå– JSON å°è±¡
            m = re.search(r"\{[\s\S]*?\}", t_text)
            if m:
                try:
                    thinker_analysis = json.loads(m.group(0))
                except json.JSONDecodeError:
                    thinker_analysis = {"creative_direction": "error parsing"}
            else:
                thinker_analysis = {"creative_direction": "error parsing"}
        
        total_tokens += t_tokens
        thinker_tokens_sum += t_tokens
        thinker_results[group_id] = {
            'persona': thinker_persona,
            'analysis': thinker_analysis,
            'tokens': t_tokens
        }
    
    if not silent:
        print(f" å®Œæˆ")
        print(f"   â€¢ Researcher: {r_tokens} tokens")
        print(f"   â€¢ Thinkers: {thinker_tokens_sum} tokens (G1:{thinker_results[1]['tokens']}, G2:{thinker_results[2]['tokens']}, G3:{thinker_results[3]['tokens']})")
    
    # ä¸¦è¡ŒåŸ·è¡Œ Deciders
    if not silent:
        print(f"   éšæ®µ 2ï¼šDeciders ä¸¦è¡Œ...", end="", flush=True)
    
    answers_json = json.dumps(answers, ensure_ascii=False, separators=(',',':'))
    
    decider_futures = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        for group_id, thinker_result in thinker_results.items():
            thinker_persona = thinker_result['persona']
            thinker_analysis = thinker_result['analysis']
            analysis_json = json.dumps(thinker_analysis, ensure_ascii=False, separators=(',',':'))
            
            d_prompt = (trivia_decider_prompt
                .replace("{topic}", topic)
                .replace("{researcher_answers}", answers_json)
                .replace("{thinker_analysis}", analysis_json))
            
            future = executor.submit(nano_run, "", d_prompt, model_fn)
            decider_futures.append((future, group_id, thinker_persona))
        
        final_results = {}
        for future, group_id, thinker_persona in decider_futures:
            try:
                d_text, d_tokens, _ = future.result()
                total_tokens += d_tokens
                
                # å¢å¼· JSON è§£æå®¹éŒ¯æ€§
                if d_text.startswith('{{') and d_text.endswith('}}'):
                    d_text = d_text[1:-1]
                
                try:
        out = json.loads(d_text)
                except json.JSONDecodeError:
                    # å˜—è©¦æå– JSON å°è±¡
                    m = re.search(r"\{[\s\S]*?\}", d_text)
                    if m:
                        out = json.loads(m.group(0))
                    else:
                        raise ValueError("ç„¡æ³•è§£æ JSON")
                
                final_story = out.get("final_story","").strip()
                
                final_results[group_id] = {
                    'thinker_persona': thinker_persona,
                    'final_story': final_story,
                    'tokens': d_tokens
                }
                
                    
    except Exception as e:
                final_results[group_id] = {
                    'thinker_persona': thinker_persona,
                    'final_story': "",
                    'tokens': 0,
                    'error': str(e)
                }
    
    # è¨ˆç®— Decider tokens
    decider_tokens_sum = sum(r.get('tokens', 0) for r in final_results.values())
    
    if not silent:
        print(f" å®Œæˆ")
        decider_tokens_list = [final_results.get(i, {}).get('tokens', 0) for i in [1, 2, 3]]
        print(f"   â€¢ Deciders: {decider_tokens_sum} tokens (G1:{decider_tokens_list[0]}, G2:{decider_tokens_list[1]}, G3:{decider_tokens_list[2]})")

    results.update({
        "answers": answers,
        "final_results": final_results,
        "tokens": total_tokens
    })
    
    return results


def test_trivia_full() -> None:
    """æ¸¬è©¦ Trivia å®Œæ•´æµç¨‹ï¼ˆå–®æ¬¡ï¼‰"""
    if not OPENAI_API_KEY:
        raise RuntimeError("è«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEYã€‚")

    # è®€å–é¡Œåº«
    data = load_trivia_test_data()
    idx = random.randint(0, len(data) - 1)
    item = data[idx]
    topic = item.get("topic", "General")
    questions = item.get("questions", [])
    
    print("=== TRIVIA æ¸¬è©¦ ===")
    print(f"é¡Œçµ„ #{idx+1} | ä¸»é¡Œ: {topic} | å•é¡Œæ•¸: {len(questions)}\n")

    # åˆå§‹åŒ–æ¨¡å‹å‡½å¼
    model_fn = build_openai_model_fn(MODEL_NAME)

    # æ­¥é©Ÿ 1ï¼šç”Ÿæˆäººæ ¼ç¾¤çµ„ï¼ˆä½¿ç”¨é€²åº¦æ¢ï¼‰
    print("ğŸ”¹ æ­¥é©Ÿ 1: ç”Ÿæˆäººæ ¼ç¾¤çµ„", end="", flush=True)
    switch_prompt = trivia_personas_switch_prompt.replace("{topic}", topic)
    switch_result, switch_tokens, _ = nano_run(persona="", user_text=switch_prompt, model_fn=model_fn)
    print(f" âœ“ ({switch_tokens} tokens)")
    
    # è§£æäººæ ¼ç¾¤çµ„
    try:
        personas_data = json.loads(switch_result)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", switch_result, flags=re.S)
        if m:
            try:
                personas_data = json.loads(m.group(0))
            except json.JSONDecodeError:
                personas_data = {"groups": [{"group_id": 1, "thinker": "Narrative Essayist"}]}
        else:
            personas_data = {"groups": [{"group_id": 1, "thinker": "Narrative Essayist"}]}
    
    # é¡¯ç¤ºç”Ÿæˆçš„ Thinker
    groups = personas_data.get("groups", [])
    for group in groups:
        group_id = group.get('group_id', 0)
        thinker = group.get('thinker', 'Unknown')
        print(f"   Group {group_id}'s thinker: {thinker}")
    
    # æ­¥é©Ÿ 2ï¼šå¤šç¾¤çµ„æµç¨‹
    result = run_trivia_multi_group_flow(model_fn, topic, questions, personas_data, silent=False)

    if "error" in result:
        print("âŒ æµç¨‹éŒ¯èª¤:", result["error"])
        return
    
    # é¡¯ç¤º Researcher ç­”æ¡ˆ
    answers = result.get("answers", [])
    print(f"\nğŸ“‹ Researcher ç­”æ¡ˆ: {answers}")
    
    # æ­¥é©Ÿ 3: Mini Mux è©•æ¯”
    print(f"\nğŸ”¹ æ­¥é©Ÿ 3: Mini Mux è©•æ¯”", end="", flush=True)
    
    mini_model_fn = build_openai_model_fn(MINI_MODEL_NAME)
    
    # æ”¶é›† researcher çš„äº‹å¯¦ç­”æ¡ˆ
    facts = result.get("answers", [])
    
    # æ”¶é›†ä¸‰çµ„æ•…äº‹
    stories = []
    final_results = result.get("final_results", {})
    
    for group_id in sorted(final_results.keys()):
        group_result = final_results[group_id]
        if "error" not in group_result:
            story = group_result.get("final_story", "")
            stories.append(story)
    else:
            stories.append("")
    
    while len(stories) < 3:
        stories.append("")
    
    # åŸ·è¡Œ Mini Mux
    try:
        minimux_result, minimux_tokens, _ = mini_mux(
            facts, stories, trivia_minimux_prompt, mini_model_fn
        )
        
        print(f" âœ“ ({minimux_tokens} tokens)")
        
        # è§£ææœ€ä½³çµ„åˆ¥
        try:
            minimux_data = json.loads(minimux_result)
        except json.JSONDecodeError:
            m = re.search(r"\{[\s\S]*?\}", minimux_result)
            if m:
                try:
                    minimux_data = json.loads(m.group(0))
                except json.JSONDecodeError:
                    minimux_data = None
        else:
                minimux_data = None
        
        if minimux_data:
            best_group = minimux_data.get("best_group", 1)
            print(f"\nğŸ† æœ€ä½³çµ„åˆ¥: Group {best_group}")
            
            if best_group in final_results:
                best_story = final_results[best_group].get("final_story", "")
                print(f"ğŸ“– æ•…äº‹: {best_story}")
    except Exception as e:
        print(f"âŒ Mini Mux éŒ¯èª¤: {e}")
        minimux_tokens = 0
    
    print(f"\nç¸½ Token æ¶ˆè€—: {result['tokens'] + switch_tokens + minimux_tokens} (Switch: {switch_tokens} + æµç¨‹: {result['tokens']} + Mini Mux: {minimux_tokens})")


def test_trivia_batch() -> None:
    """æ‰¹æ¬¡æ¸¬è©¦æ‰€æœ‰ 100 é¡Œï¼Œè¨ˆç®—æº–ç¢ºåº¦"""
    if not OPENAI_API_KEY:
        raise RuntimeError("è«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEYã€‚")
    
    print("=== TRIVIA æ‰¹æ¬¡æ¸¬è©¦ (100 é¡Œ) ===\n")
    
    # è®€å–é¡Œåº«
    data = load_trivia_test_data()
    total_groups = len(data)
    
    model_fn = build_openai_model_fn(MODEL_NAME)
    mini_model_fn = build_openai_model_fn(MINI_MODEL_NAME)
    
    # çµ±è¨ˆè®Šæ•¸
    total_tokens = 0
    correct_count = 0
    total_questions = 0
    error_count = 0
    
    # ç·¨è­¯æ­£å‰‡è¡¨é”å¼ï¼ˆçœæ™‚é–“ï¼‰
    puncts = re.compile(r'[^\w\s]')
    spaces = re.compile(r'\s+')
    stopwords = re.compile(r'\b(the|a|an|and|or|of|in|on|at|to|for|with|by)\b')
    
    def normalize_answer(ans: str) -> str:
        """æ­£è¦åŒ–ç­”æ¡ˆ"""
        if not ans:
            return ""
        s = str(ans).lower().strip()
        s = puncts.sub('', s)
        s = stopwords.sub(' ', s)
        s = spaces.sub(' ', s).strip()
        return s
    
    print(f"é–‹å§‹æ¸¬è©¦ {total_groups} çµ„...\n")
    
    for idx, item in enumerate(data):
        topic = item.get("topic", "General")
        questions = item.get("questions", [])
        correct_answers_list = item.get("answers", [])
        
        # è¨ˆç®—å³æ™‚æº–ç¢ºåº¦
        current_accuracy = (correct_count / total_questions * 100) if total_questions > 0 else 0
        
        # é€²åº¦æ¢é¡¯ç¤º
        percent = (idx / total_groups)
        filled = int(30 * percent)
        bar = "â–ˆ" * filled + "â–‘" * (30 - filled)
        print(f"\ré€²åº¦: |{bar}| {idx}/{total_groups} ({percent*100:.1f}%) | æº–ç¢ºåº¦: {current_accuracy:.1f}% | {topic[:20]:<20}", end="", flush=True)
        
        try:
            # æ­¥é©Ÿ 1: ç”Ÿæˆäººæ ¼ç¾¤çµ„
            switch_prompt = trivia_personas_switch_prompt.replace("{topic}", topic)
            switch_result, switch_tokens, _ = nano_run(persona="", user_text=switch_prompt, model_fn=model_fn)
            total_tokens += switch_tokens
            
            # è§£æäººæ ¼ç¾¤çµ„
            try:
                personas_data = json.loads(switch_result)
            except json.JSONDecodeError:
                m = re.search(r"\{.*\}", switch_result, flags=re.S)
                personas_data = json.loads(m.group(0)) if m else {"groups": [{"group_id": 1, "thinker": "Essayist"}]}
            
            # æ­¥é©Ÿ 2: åŸ·è¡Œå¤šç¾¤çµ„æµç¨‹
            result = run_trivia_multi_group_flow(model_fn, topic, questions, personas_data, silent=True)
            total_tokens += result.get('tokens', 0)
            
    if "error" in result:
                error_count += 1
                continue
            
            # å–å¾— researcher ç­”æ¡ˆ
            researcher_answers = result.get('answers', [])
            
            # ç­”æ¡ˆé è™•ç†ï¼šè£åˆ‡åˆ°æ­£ç¢ºé•·åº¦
            researcher_answers = researcher_answers[:len(questions)]
            
            # æ­¥é©Ÿ 3: Mini Muxï¼ˆè¨ˆå…¥ tokenï¼Œä½†ä¸å½±éŸ¿æº–ç¢ºåº¦åˆ¤æ–·ï¼‰
            stories = []
            for group_id in sorted(result.get("final_results", {}).keys()):
                story = result["final_results"][group_id].get("final_story", "")
                stories.append(story if story else "")
            while len(stories) < 3:
                stories.append("")
            
            try:
                _, minimux_tokens, _ = mini_mux(researcher_answers, stories, trivia_minimux_prompt, mini_model_fn)
                total_tokens += minimux_tokens
            except:
                pass  # Mini Mux å¤±æ•—ä¸å½±éŸ¿æº–ç¢ºåº¦
            
            # è¨ˆç®—æº–ç¢ºåº¦ï¼ˆé€é¡Œæ¯”å°ï¼‰
            group_correct = 0
            for i, researcher_ans in enumerate(researcher_answers):
                researcher_norm = normalize_answer(researcher_ans)
                if not researcher_norm:
                    continue
                
                # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ­£ç¢ºç­”æ¡ˆ
                for correct_ans in correct_answers_list[i]:
                    correct_norm = normalize_answer(correct_ans)
                    # ç²¾ç¢ºåŒ¹é…ã€åŒ…å«åŒ¹é…æˆ–é—œéµè©åŒ¹é…
                    if (researcher_norm == correct_norm or 
                        researcher_norm in correct_norm or 
                        correct_norm in researcher_norm):
                        group_correct += 1
                        break
                    # é—œéµè©åŒ¹é…ï¼ˆé•·åº¦>2çš„è©ï¼‰
                    researcher_words = [w for w in researcher_norm.split() if len(w) > 2]
                    correct_words = [w for w in correct_norm.split() if len(w) > 2]
                    if any(w in correct_norm for w in researcher_words) or \
                       any(w in researcher_norm for w in correct_words):
                        group_correct += 1
                        break
            
            correct_count += group_correct
            total_questions += len(questions)
                
        except Exception as e:
            error_count += 1
    
    # å®Œæˆé€²åº¦æ¢
    bar = "â–ˆ" * 30
    final_accuracy = (correct_count / total_questions * 100) if total_questions > 0 else 0
    print(f"\ré€²åº¦: |{bar}| {total_groups}/{total_groups} (100.0%) | æº–ç¢ºåº¦: {final_accuracy:.1f}% | å®Œæˆ!{' '*20}")
    
    # æœ€çµ‚çµ±è¨ˆ
    print(f"\n{'='*50}")
    print(f"æ¸¬è©¦å®Œæˆï¼")
    print(f"ç¸½é¡Œçµ„: {total_groups} | æˆåŠŸ: {total_groups - error_count} | éŒ¯èª¤: {error_count}")
    print(f"ç¸½å•é¡Œæ•¸: {total_questions}")
    print(f"æ­£ç¢ºç­”æ¡ˆ: {correct_count}")
    print(f"æº–ç¢ºåº¦: {final_accuracy:.1f}%")
    print(f"ç¸½ Token: {total_tokens:,} | å¹³å‡/çµ„: {total_tokens/total_groups:.0f}")
    print(f"{'='*50}")


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    print("è«‹é¸æ“‡æ¸¬è©¦æ¨¡å¼:")
    print("1. trivia - å–®é¡Œå®Œæ•´æ¸¬è©¦")
    print("2. batch - æ‰¹æ¬¡æ¸¬è©¦ï¼ˆ100é¡Œï¼‰\n")
    
    mode = input("è«‹è¼¸å…¥ 'trivia' æˆ– 'batch': ").strip().lower()
    
    if mode == "trivia":
        test_trivia_full()
    elif mode == "batch":
        test_trivia_batch()
    else:
        print("ç„¡æ•ˆé¸é …ï¼ŒåŸ·è¡Œå–®é¡Œæ¸¬è©¦...")
        test_trivia_full()


if __name__ == "__main__":
    main()
