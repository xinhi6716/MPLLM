import os
import json
import random
import re
import csv
import datetime
import time
import concurrent.futures
from typing import Dict, Any, List, Tuple

from mpllm_prompts.nano import nano_run, mini_mux
from mpllm_prompts.switch_prompts import trivia_personas_switch_prompt
from mpllm_prompts.prompts import (
    trivia_researcher_prompt,
    trivia_thinker_prompt,
    trivia_minimux_prompt,
)

# API è¨­å®š
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "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")
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
MODEL_NAME = os.environ.get("MODEL_NAME", "gpt-4.1-mini")
MINI_MODEL_NAME = os.environ.get("MINI_MODEL_NAME", "gpt-4.1-mini")

# OpenAI å®¢æˆ¶ç«¯è¨­å®š
try:
    from openai import OpenAI
    _use_openai_v1 = True
except Exception:
    _use_openai_v1 = False
    import openai


def build_openai_model_fn(model: str):
    """å»ºç«‹ OpenAI æ¨¡å‹å‡½æ•¸"""
    if _use_openai_v1:
        client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)

        def _model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=5000,  # é€²ä¸€æ­¥å¢åŠ è¼¸å‡ºé•·åº¦é™åˆ¶
            )
            choice = resp.choices[0] if resp.choices else None
            text = (choice.message.content or "").strip() if choice and choice.message else ""
            
            usage = getattr(resp, "usage", None)
            total_tokens = int(getattr(usage, "total_tokens", 0) if usage else 0)
            return text, total_tokens

        return _model_fn
    else:
        openai.api_key = OPENAI_API_KEY
        openai.api_base = OPENAI_BASE_URL

        def _model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
            resp = openai.ChatCompletion.create(model=model, messages=messages)
            text = (resp["choices"][0]["message"]["content"] or "").strip()
            usage = resp.get("usage") or {}
            total_tokens = int(usage.get("total_tokens") or 0)
            return text, total_tokens

        return _model_fn


def load_trivia_test_data():
    """è¼‰å…¥ trivia æ¸¬è©¦è³‡æ–™"""
    path = "./data/trivia_creative_writing/trivia_creative_writing_100_n_5.jsonl"
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f]


# ===== æ¨¡å¡ŠåŒ–æµç¨‹å‡½æ•¸ =====
def run_switch_phase(model_fn, topic: str, verbose: bool = False) -> Tuple[Dict[str, Any], int]:
    """éšæ®µ 1: ç”Ÿæˆè§’è‰²ç¾¤çµ„

    Returns:
        (personas_data, tokens)
        personas_data æ ¼å¼: {"groups": [{"g": 1, "r": "...", "t": "..."}]}
    """
    # å‹•æ…‹ç”Ÿæˆè§’è‰²çµ„åˆ
    switch_prompt = trivia_personas_switch_prompt.replace("{topic}", topic)
    
    # å»ºç«‹é™åˆ¶ output tokens çš„ model_fnï¼ˆç”¨æ–¼ Switchï¼‰
    def limited_switch_model_fn(messages):
        if _use_openai_v1:
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
            resp = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                max_completion_tokens=900,  # Switch åªéœ€è¦ç°¡çŸ­çš„ JSONï¼ˆç´„ 50-150 tokensï¼‰
            )
            text = (resp.choices[0].message.content or "").strip()
            usage = getattr(resp, "usage", None)
            total_tokens = int(getattr(usage, "total_tokens", 0) if usage else 0)
            return text, total_tokens
        else:
            import openai
            openai.api_key = OPENAI_API_KEY
            openai.api_base = OPENAI_BASE_URL
            resp = openai.ChatCompletion.create(
                model=MINI_MODEL_NAME,
                messages=messages,
                max_tokens=900  # Switch åªéœ€è¦ç°¡çŸ­çš„ JSONï¼ˆç´„ 50-150 tokensï¼‰
            )
            text = (resp["choices"][0]["message"]["content"] or "").strip()
            usage = resp.get("usage") or {}
            total_tokens = int(usage.get("total_tokens", 0))
            return text, total_tokens
    
    switch_result, switch_tokens, _ = nano_run(persona="", user_text=switch_prompt, model_fn=limited_switch_model_fn)
    
    # è§£æè§’è‰²
    try:
        personas_data = json.loads(switch_result)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", switch_result, flags=re.S)
        if m:
            try:
                personas_data = json.loads(m.group(0))
            except json.JSONDecodeError:
                # ä½¿ç”¨å‚™ç”¨è§’è‰²çµ„åˆ
                personas_data = {
                    "groups": [
                        {"g": 1, "r": "Fact Expert", "t": "Story Weaver"},
                        {"g": 2, "r": "Data Scholar", "t": "Tale Scribe"},
                        {"g": 3, "r": "Knowledge Keeper", "t": "Myth Builder"},
                    ]
                }
        else:
            # ä½¿ç”¨å‚™ç”¨è§’è‰²çµ„åˆ
            personas_data = {
                "groups": [
                    {"g": 1, "r": "Fact Expert", "t": "Story Weaver"},
                    {"g": 2, "r": "Data Scholar", "t": "Tale Scribe"},
                    {"g": 3, "r": "Knowledge Keeper", "t": "Myth Builder"},
                ]
            }


    # é¡¯ç¤ºç”Ÿæˆçš„è§’è‰²ç¾¤çµ„ï¼ˆåƒ…åœ¨ verbose æ¨¡å¼ä¸‹ï¼‰
    if verbose:
        print("æ­¥é©Ÿ 1: ç”Ÿæˆè§’è‰²ç¾¤çµ„")
        for group in personas_data.get("groups", []):
            group_id = group.get("g", 0)
            researcher = group.get("r", "Unknown")
            thinker = group.get("t", "Unknown")
            print(f"   ç¾¤çµ„{group_id}: {researcher} | {thinker}")
    
    return personas_data, switch_tokens


def get_role_name(role):
    """å¾è§’è‰²æ•¸æ“šä¸­æå–å­—ç¬¦ä¸²åç¨±ï¼Œè™•ç† LLM å¯èƒ½è¿”å›çš„åˆ—è¡¨æ ¼å¼"""
    if isinstance(role, str):
        return role
    elif isinstance(role, list) and len(role) > 0:
        return str(role[0])
    else:
        return str(role) if role else "Expert"


def run_researcher_thinker_phase(
    model_fn,
    personas_data: Dict[str, Any],
    topic: str,
    questions: List[str],
    verbose: bool = False,
) -> Tuple[List[List[str]], Dict[int, Dict], int]:
    """éšæ®µ 2: ä¸¦è¡ŒåŸ·è¡Œ Researcher (åˆä½µ) + Thinker

    Returns:
        (researcher_answers_list, thinker_results, total_tokens)
        researcher_answers_list: 3çµ„ç­”æ¡ˆåˆ—è¡¨ [["ans1", "ans2", ...], [...], [...]]
        thinker_results: {group_id: {'persona': ..., 'analysis': {...}, 'tokens': ...}}
    """
    groups = personas_data.get("groups", [])

    # æº–å‚™åˆä½µç‰ˆ Researcher promptï¼ˆä¸€æ¬¡èª¿ç”¨å¾—åˆ°3çµ„ç­”æ¡ˆï¼‰
    r1 = get_role_name(groups[0].get("r", "Expert1"))
    r2 = get_role_name(groups[1].get("r", "Expert2"))
    r3 = get_role_name(groups[2].get("r", "Expert3"))
    
    # æ ¼å¼åŒ–å•é¡Œåˆ—è¡¨ç‚ºæ˜“è®€æ ¼å¼
    questions_formatted = "\n".join([f"{i+1}. {q}" for i, q in enumerate(questions)])
    
    researcher_prompt = (
        trivia_researcher_prompt
        .replace("{r1}", r1)
        .replace("{r2}", r2)
        .replace("{r3}", r3)
        .replace("{questions}", questions_formatted)
    )

    # æº–å‚™ Thinker prompts
    thinker_prompt = trivia_thinker_prompt.replace("{topic}", topic)

    # å»ºç«‹é™åˆ¶ output tokens çš„ model_fnï¼ˆç”¨æ–¼ Thinkerï¼‰
    def limited_thinker_model_fn(messages: List[Dict[str, str]]) -> Tuple[str, int]:
        if _use_openai_v1:
            client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
            resp = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                max_completion_tokens=1500,
            )
            text = (resp.choices[0].message.content or "").strip()
            usage = getattr(resp, "usage", None)
            total_tokens = int(getattr(usage, "total_tokens", 0) if usage else 0)
            return text, total_tokens
        else:
            openai.api_key = OPENAI_API_KEY
            openai.api_base = OPENAI_BASE_URL
            resp = openai.ChatCompletion.create(
                model=MODEL_NAME,
                messages=messages,
                max_tokens=1500,
            )
            text = (resp["choices"][0]["message"]["content"] or "").strip()
            usage = resp.get("usage") or {}
            total_tokens = int(usage.get("total_tokens") or 0)
            return text, total_tokens

    def run_researchers_combined():
        """ä¸€æ¬¡èª¿ç”¨åŸ·è¡Œæ‰€æœ‰3å€‹researcher"""
        try:
            result, tokens, messages = nano_run(persona="", user_text=researcher_prompt, model_fn=model_fn)
            
            # å¦‚æœè¼¸å‡ºç‚ºç©ºï¼Œè¿”å›éŒ¯èª¤æ¨™è¨˜
            if not result or len(result) == 0:
                return "researchers", 0, "combined", '{"r1":[],"r2":[],"r3":[]}', tokens
            return "researchers", 0, "combined", result, tokens
        except Exception as e:
            # è¿”å›ç©ºçµæœ
            return "researchers", 0, "combined", '{"r1":[],"r2":[],"r3":[]}', 0

    def run_thinker(group_id, thinker_persona):
        personalized_prompt = thinker_prompt.replace("{thinker_persona}", thinker_persona)
        try:
            result, tokens, _ = nano_run(persona="", user_text=personalized_prompt, model_fn=limited_thinker_model_fn)
        except Exception as e:
            result, tokens = "", 0
        return "thinker", group_id, thinker_persona, result, tokens

    # ä¸¦è¡ŒåŸ·è¡Œ
    phase_results: Dict[str, Dict[str, Any]] = {}
    total_tokens = 0

    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = []

        # æäº¤åˆä½µç‰ˆ Researcher ä»»å‹™ï¼ˆåª1å€‹ï¼‰
        researcher_future = executor.submit(run_researchers_combined)
        futures.append((researcher_future, "researchers", 0))

        # æäº¤ Thinker ä»»å‹™ï¼ˆ3å€‹ï¼‰
        for i, group in enumerate(groups):
            thinker_persona = get_role_name(group.get("t", "Writer"))
            future = executor.submit(run_thinker, i + 1, thinker_persona)
            futures.append((future, "thinker", i + 1))

        # æ”¶é›†çµæœ
        for future in concurrent.futures.as_completed([f[0] for f in futures]):
            for task_future, task_type, group_id in futures:
                if future == task_future:
                    try:
                        task_type, group_id, persona, result, tokens = future.result()
                        total_tokens += tokens

                        if task_type == "researchers":
                            # è™•ç†åˆä½µç‰ˆ researcher çµæœ
                            phase_results["researchers_combined"] = {
                                "persona": "Combined Researchers",
                                "result": result,
                                "tokens": tokens,
                            }
                        else:
                            # è™•ç† thinker çµæœ
                            phase_results[f"thinker_{group_id}"] = {
                                "persona": persona,
                                "result": result,
                                "tokens": tokens,
                            }
                    except Exception as e:
                        if task_type == "researchers":
                            phase_results["researchers_combined"] = {
                                "persona": "Error",
                                "result": '{"r1":[],"r2":[],"r3":[]}',
                                "tokens": 0,
                                "error": str(e),
                            }
                        else:
                            phase_results[f"thinker_{group_id}"] = {
                                "persona": "Error",
                                "result": '{"creative_direction": "error"}',
                                "tokens": 0,
                                "error": str(e),
                            }
                    break

    # æå– Researcher ç­”æ¡ˆï¼ˆå¾åˆä½µçµæœä¸­ï¼‰
    researcher_answers_list: List[List[str]] = [[], [], []]
    if "researchers_combined" in phase_results:
        raw_result = phase_results["researchers_combined"]["result"]
        
        try:
            combined_data = json.loads(raw_result)
            researcher_answers_list[0] = combined_data.get("r1", [])
            researcher_answers_list[1] = combined_data.get("r2", [])
            researcher_answers_list[2] = combined_data.get("r3", [])
            
        except json.JSONDecodeError as e:
            # å˜—è©¦ç”¨æ­£å‰‡è¡¨é”å¼æå–
            m = re.search(r"\{[\s\S]*?\}", raw_result)
            if m:
                try:
                    combined_data = json.loads(m.group(0))
                    researcher_answers_list[0] = combined_data.get("r1", [])
                    researcher_answers_list[1] = combined_data.get("r2", [])
                    researcher_answers_list[2] = combined_data.get("r3", [])
                    
                except json.JSONDecodeError:
                    pass

    # æå– Thinker çµæœ
    thinker_results: Dict[int, Dict[str, Any]] = {}
    for i, _group in enumerate(groups):
        group_id = i + 1
        thinker_key = f"thinker_{group_id}"
        if thinker_key in phase_results:
            t_result = phase_results[thinker_key]
            
            # å…ˆè™•ç†è¼¸å‡º
            raw_result = t_result["result"].strip()
            
            # ç§»é™¤é›™å¤§æ‹¬è™Ÿ
            if raw_result.startswith("{{") and raw_result.endswith("}}"):
                raw_result = raw_result[1:-1]
            
            try:
                analysis = json.loads(raw_result)
            except json.JSONDecodeError:
                # è™•ç†å¤šç¨®å¯èƒ½çš„æ ¼å¼
                cleaned = raw_result.strip()
                
                # 1. å˜—è©¦ç§»é™¤å¤–å±¤é›™å¤§æ‹¬è™Ÿ
                if cleaned.startswith("{{") and cleaned.endswith("}}"):
                    cleaned = cleaned[1:-1]
                
                # 2. å¦‚æœæœ‰å¤šè¡Œï¼Œå˜—è©¦æå–æœ€å¾Œä¸€è¡Œçš„ JSON
                if "\n" in cleaned:
                    lines = cleaned.split("\n")
                    for line in reversed(lines):  # å¾å¾Œå¾€å‰æ‰¾
                        line = line.strip()
                        if line.startswith("{"):
                            cleaned = line
                            break
                
                # 3. ç§»é™¤ç¬¬äºŒå±¤é›™å¤§æ‹¬è™Ÿï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if cleaned.startswith("{{") and cleaned.endswith("}}"):
                    cleaned = cleaned[1:-1]
                
                try:
                    analysis = json.loads(cleaned)
                except json.JSONDecodeError:
                    # 4. æœ€å¾Œç”¨æ­£å‰‡è¡¨é”å¼æå–
                    m = re.search(r"\{[^{}]*creative_direction[^{}]*\}", cleaned)
                    if m:
                        try:
                            analysis = json.loads(m.group(0))
                        except json.JSONDecodeError:
                            analysis = {"creative_direction": "error parsing"}
                    else:
                        analysis = {"creative_direction": "error parsing"}

            thinker_results[group_id] = {
                "persona": t_result["persona"],
                "analysis": analysis,
                "tokens": t_result["tokens"],
            }

    return researcher_answers_list, thinker_results, total_tokens


def run_decider_phase(
    model_fn,
    personas_data: Dict[str, Any],
    topic: str,
    researcher_answers_list: List[List[str]],
    thinker_results: Dict[int, Dict],
    verbose: bool = False,
) -> Tuple[Dict[int, Dict], int]:
    """éšæ®µ 3: ä¸¦è¡ŒåŸ·è¡Œ Deciderï¼ˆå·²å»¢æ£„ï¼Œä¸å†ä½¿ç”¨ï¼‰

    Returns:
        (decider_results, total_tokens)
        decider_results: {group_id: {'decider_persona': ..., 'thinker_persona': ..., 'final_story': "...", 'tokens': ...}}
    
    Note: æ­¤å‡½æ•¸å·²ä¸å†ä½¿ç”¨ï¼Œä¿ç•™åƒ…ä¾›åƒè€ƒã€‚å¦‚éœ€æ¢å¾© Decider éšæ®µï¼Œéœ€é‡æ–° import trivia_decider_promptã€‚
    """
    # æ­¤å‡½æ•¸å·²å»¢æ£„ï¼Œç›´æ¥è¿”å›ç©ºçµæœ
    # å¦‚éœ€æ¢å¾© Decider éšæ®µï¼Œè«‹åƒè€ƒ git æ­·å²è¨˜éŒ„ä¸­çš„å®Œæ•´å¯¦ç¾ï¼Œä¸¦é‡æ–° import trivia_decider_prompt
    return {}, 0


def run_minimux_phase(mini_model_fn, topic, questions, researcher_answers_list, thinker_results, verbose=False):
    """éšæ®µ 3: Mini Mux è©•æ¯”ï¼ˆç›´æ¥ä½¿ç”¨ Thinker åˆ†æï¼Œä¸ä½¿ç”¨ Deciderï¼‰"""
    q_json  = json.dumps(questions, ensure_ascii=False, separators=(',',':'))
    r1_json = json.dumps(researcher_answers_list[0] if len(researcher_answers_list) > 0 else [], ensure_ascii=False, separators=(',',':'))
    r2_json = json.dumps(researcher_answers_list[1] if len(researcher_answers_list) > 1 else [], ensure_ascii=False, separators=(',',':'))
    r3_json = json.dumps(researcher_answers_list[2] if len(researcher_answers_list) > 2 else [], ensure_ascii=False, separators=(',',':'))

    def clip_text(s: str, max_words=20):
        """è£åˆ‡æ–‡å­—åˆ°æŒ‡å®šå­—æ•¸"""
        ws = re.findall(r"\S+", s or "")
        return " ".join(ws[:max_words])

    # ä½¿ç”¨ Thinker çš„ creative_direction è€Œä¸æ˜¯ Decider æ•…äº‹
    t1 = clip_text(thinker_results.get(1,{}).get('analysis',{}).get('creative_direction',''), 20)
    t2 = clip_text(thinker_results.get(2,{}).get('analysis',{}).get('creative_direction',''), 20)
    t3 = clip_text(thinker_results.get(3,{}).get('analysis',{}).get('creative_direction',''), 20)

    # åŸ·è¡Œ Mini Muxï¼ˆå‚³å…¥ topic å’Œ Thinker åˆ†æï¼‰
    minimux_result, minimux_tokens, _ = mini_mux(trivia_minimux_prompt, mini_model_fn, 
                                            topic=topic, questions=q_json, 
                                            researcher1=r1_json, R1=r1_json,
                                            researcher2=r2_json, R2=r2_json,
                                            researcher3=r3_json, R3=r3_json,
                                            thinker1=t1, thinker2=t2, thinker3=t3)

    # è§£æ Mini Mux çµæœ
    try:
        minimux_data = json.loads(minimux_result)
    except json.JSONDecodeError:
        m = re.search(r"\{[\s\S]*?\}", minimux_result)
        if m:
            try:
                minimux_data = json.loads(m.group(0))
            except json.JSONDecodeError:
                minimux_data = {"final_answers": [], "final_story": "è§£æå¤±æ•—"}
        else:
            minimux_data = {"final_answers": [], "final_story": "è§£æå¤±æ•—"}


    return minimux_data, minimux_tokens


# ===== æ¸¬è©¦å‡½æ•¸ =====
def normalize_answer(ans: str) -> str:
    """æ­£è¦åŒ–ç­”æ¡ˆ"""
    if not ans:
        return ""
    s = str(ans).lower().strip()
    s = re.sub(r"[^\w\s]", "", s)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    s = re.sub(r"\b(the|a|an|and|or|of|in|on|at|to|for|with|by)\b", " ", s)  # ç§»é™¤åœç”¨è©
    s = re.sub(r"\s+", " ", s).strip()  # æ­£è¦åŒ–ç©ºæ ¼
    return s


def test_trivia():
    """å–®é¡Œå®Œæ•´æ¸¬è©¦ï¼ˆä½¿ç”¨æ¨¡å¡ŠåŒ–æµç¨‹ï¼‰"""
    print("=== TRIVIA å–®é¡Œæ¸¬è©¦ ===")
    print("=" * 50)

    # è¼‰å…¥æ¸¬è©¦è³‡æ–™
    test_data = load_trivia_test_data()
    if not test_data:
        print("ç„¡æ³•è¼‰å…¥æ¸¬è©¦è³‡æ–™")
        return

    # éš¨æ©Ÿé¸ä¸€é¡Œæ¸¬è©¦
    item = random.choice(test_data)
    topic = item.get("topic", "General")
    questions = item.get("questions", [])
    correct_answers_list = item.get("answers", [])

    print(f"ä¸»é¡Œ: {topic}")
    print(f"å•é¡Œæ•¸: {len(questions)}")
    print()

    # è¨­å®šæ¨¡å‹
    model_fn = build_openai_model_fn(MODEL_NAME)
    mini_model_fn = build_openai_model_fn(MINI_MODEL_NAME)

    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()

    # åŸ·è¡Œå››å€‹éšæ®µ
    personas_data, switch_tokens = run_switch_phase(model_fn, topic, verbose=True)
    print()

    print("æ­¥é©Ÿ 2: ä¸¦è¡ŒåŸ·è¡Œ Researcher + Thinker", end="", flush=True)
    researcher_answers_list, thinker_results, rt_tokens = run_researcher_thinker_phase(
        model_fn, personas_data, topic, questions, verbose=True
    )
    print(" âœ“")

    print("æ­¥é©Ÿ 3: Mini Mux è©•æ¯”", end="", flush=True)
    minimux_data, minimux_tokens = run_minimux_phase(
        mini_model_fn, topic, questions, researcher_answers_list, thinker_results, verbose=False
    )
    print(" âœ“\n")

    # è¨˜éŒ„çµæŸæ™‚é–“
    elapsed_time = time.time() - start_time

    # ç¸½çµ
    print("=" * 50)
    total_tokens = switch_tokens + rt_tokens + minimux_tokens
    print(f"\nâ±ï¸  åŸ·è¡Œæ™‚é–“: {elapsed_time:.2f}ç§’ ({elapsed_time/60:.2f}åˆ†é˜)")
    
    # ç­”æ¡ˆæ¯”å°
    final_answers = minimux_data.get("final_answers", [])
    correct_count = 0
    total_questions_count = len(questions)
    
    print(f"\nâœ… ç­”æ¡ˆæ¯”å°:")
    for i, final_ans in enumerate(final_answers):
        if i >= len(correct_answers_list):
            break
        
        final_norm = normalize_answer(final_ans)
        if not final_norm:
            status = "âŒ"
            continue
        
        # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ­£ç¢ºç­”æ¡ˆ
        matched = False
        for correct_ans in correct_answers_list[i]:
            correct_norm = normalize_answer(correct_ans)
            
            # ç²¾ç¢º/åŒ…å«åŒ¹é…
            if (
                final_norm == correct_norm
                or final_norm in correct_norm
                or correct_norm in final_norm
            ):
                correct_count += 1
                matched = True
                status = "âœ“"
                break
            
            # é—œéµè©åŒ¹é…ï¼ˆé•·åº¦>2çš„è©ï¼‰
            final_words = [w for w in final_norm.split() if len(w) > 2]
            correct_words = [w for w in correct_norm.split() if len(w) > 2]
            if any(w in correct_norm for w in final_words) or any(w in final_norm for w in correct_words):
                correct_count += 1
                matched = True
                status = "âœ“"
                break
        
        if not matched:
            status = "âœ—"
        
        print(f"   å•é¡Œ {i+1}: {status} | é æ¸¬: {final_ans[:30]:<30} | æ­£ç¢º: {', '.join(correct_answers_list[i][:2])}")
    
    # é¡¯ç¤ºæº–ç¢ºç‡
    accuracy = (correct_count / total_questions_count * 100) if total_questions_count > 0 else 0
    print(f"\nğŸ¯ æº–ç¢ºç‡: {correct_count}/{total_questions_count} ({accuracy:.1f}%)")
    
    # ä¿å­˜å–®é¡Œçµæœåˆ° CSVï¼ˆä½¿ç”¨çµ±ä¸€æª”æ¡ˆï¼‰
    results_dir = "results"
    os.makedirs(results_dir, exist_ok=True)
    csv_path = os.path.join(results_dir, "results_trivia.csv")
    
    # ç¢ºä¿ CSV æœ‰æ¨™é ­ï¼ˆè‹¥æª”æ¡ˆä¸å­˜åœ¨ã€ç‚ºç©ºæˆ–ç¼ºæ¨™é ­å‰‡è£œä¸Šï¼‰
    header = ["æ™‚é–“", "ä¸»é¡Œ", "å•é¡Œæ•¸", "æ­£ç¢ºæ•¸", "æº–ç¢ºç‡", "ç¸½ Token", "Switch", "Researcher+Thinker", "Mini Mux", "åŸ·è¡Œæ™‚é–“(ç§’)", "æ¸¬è©¦æ¨¡å¼", "Researcherç­”æ¡ˆ", "Thinkeråˆ†æ", "Mini Muxç­”æ¡ˆ", "Mini Muxæ•…äº‹"]
    if not os.path.exists(csv_path):
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            csv.writer(f).writerow(header)
    else:
        try:
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æœ‰æ­£ç¢ºçš„ header
            with open(csv_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                existing_header = next(reader, None)
                
            # å¦‚æœæ²’æœ‰ header æˆ– header ä¸æ­£ç¢ºï¼Œå¯«å…¥æ–° header
            if not existing_header or "æ™‚é–“" not in existing_header or len(existing_header) != len(header):
                with open(csv_path, 'r+', encoding='utf-8-sig') as f:
                    content = f.read()
                    f.seek(0, 0)
                    f.write(",".join(header) + "\n" + content)
        except Exception:
            # å¦‚æœè®€å–å¤±æ•—ï¼Œç›´æ¥å»ºç«‹æ–°æª”æ¡ˆ
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                csv.writer(f).writerow(header)

    # ç²å–ç•¶å‰æ™‚é–“æˆ³
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # æº–å‚™å„éšæ®µè¼¸å‡ºå…§å®¹
    r_output = json.dumps(researcher_answers_list, ensure_ascii=False, separators=(',', ':'))
    t_output = json.dumps([thinker_results[i]["analysis"] for i in sorted(thinker_results.keys())], ensure_ascii=False, separators=(',', ':'))
    minimux_answers = json.dumps(minimux_data.get("final_answers", []), ensure_ascii=False, separators=(',', ':'))
    minimux_story = minimux_data.get("final_story", "")

    with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([
            timestamp, topic, len(questions), correct_count, f"{accuracy:.1f}%",
            total_tokens, switch_tokens, rt_tokens, minimux_tokens, f"{elapsed_time:.2f}", "single",
            r_output, t_output, minimux_answers, minimux_story
        ])
    
    print(f"\nğŸ“Š çµæœå·²å„²å­˜è‡³: {csv_path}")
    print("=" * 50)


def test_trivia_batch():
    """æ‰¹æ¬¡æ¸¬è©¦æ‰€æœ‰ 100 é¡Œï¼ˆä½¿ç”¨æ¨¡å¡ŠåŒ–æµç¨‹ï¼‰"""
    # è®€å–é¡Œåº«
    data = load_trivia_test_data()
    total_groups = len(data)

    model_fn = build_openai_model_fn(MODEL_NAME)
    mini_model_fn = build_openai_model_fn(MINI_MODEL_NAME)

    # çµ±è¨ˆè®Šæ•¸
    total_tokens = 0
    nano_tokens_total = 0
    mini_tokens_total = 0
    correct_count = 0
    total_questions = 0
    error_count = 0

    # å„éšæ®µ token çµ±è¨ˆ
    total_switch_tokens = 0
    total_rt_tokens = 0
    total_minimux_tokens = 0
    
    # æ™‚é–“çµ±è¨ˆ
    total_elapsed_time = 0.0

    # ç¢ºä¿ results è³‡æ–™å¤¾å­˜åœ¨
    results_dir = "results"
    os.makedirs(results_dir, exist_ok=True)
    
    # ä½¿ç”¨çµ±ä¸€çš„ CSV æª”æ¡ˆ
    csv_path = os.path.join(results_dir, "results_trivia.csv")

    # æª¢æŸ¥ä¸¦å¯«å…¥ CSV headerï¼ˆåªåœ¨æœ€é–‹å§‹åšä¸€æ¬¡ï¼‰
    header = ["æ™‚é–“", "ä¸»é¡Œ", "å•é¡Œæ•¸", "æ­£ç¢ºæ•¸", "æº–ç¢ºç‡", "ç¸½ Token", "Switch", "Researcher+Thinker", "Mini Mux", "åŸ·è¡Œæ™‚é–“(ç§’)", "æ¸¬è©¦æ¨¡å¼", "Researcherç­”æ¡ˆ", "Thinkeråˆ†æ", "Mini Muxç­”æ¡ˆ", "Mini Muxæ•…äº‹"]
    
    if not os.path.exists(csv_path):
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(header)
    else:
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æœ‰æ­£ç¢ºçš„ header
        try:
            with open(csv_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                existing_header = next(reader, None)
                
            # å¦‚æœæ²’æœ‰ header æˆ– header ä¸æ­£ç¢ºï¼Œå¯«å…¥æ–° header
            if not existing_header or "æ™‚é–“" not in existing_header or len(existing_header) != len(header):
                with open(csv_path, 'r+', encoding='utf-8-sig') as f:
                    content = f.read()
                    f.seek(0, 0)
                    f.write(",".join(header) + "\n" + content)
        except Exception:
            # å¦‚æœè®€å–å¤±æ•—ï¼Œç›´æ¥å»ºç«‹æ–°æª”æ¡ˆ
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(header)

    for idx, item in enumerate(data):
        topic = item.get("topic", "General")
        questions = item.get("questions", [])
        correct_answers_list = item.get("answers", [])

        # è¨ˆç®—å³æ™‚æº–ç¢ºåº¦
        current_accuracy = (correct_count / total_questions * 100) if total_questions > 0 else 0

        # é€²åº¦æ¢é¡¯ç¤º
        percent = (idx / total_groups)
        filled = int(30 * percent)
        bar = "=" * filled + "-" * (30 - filled)
        print(
            f"\ré€²åº¦: |{bar}| {idx}/{total_groups} ({percent*100:.1f}%) | æº–ç¢ºåº¦: {current_accuracy:.1f}% | {topic[:20]:<20}",
            end="",
            flush=True,
        )

        # è¨˜éŒ„ç”¨çš„è®Šæ•¸
        item_switch_tokens = 0
        item_rt_tokens = 0
        item_minimux_tokens = 0
        item_error = ""
        item_group_correct = 0
        item_error_occurred = False
        
        # è¨˜éŒ„å„éšæ®µè¼¸å‡ºå…§å®¹
        item_researcher_output = []
        item_thinker_output = []
        item_minimux_answers = []
        item_minimux_story = ""
        
        # è¨˜éŒ„å–®é¡Œé–‹å§‹æ™‚é–“
        item_start_time = time.time()

        try:
            # åŸ·è¡Œå››å€‹éšæ®µ
            personas_data, switch_tokens = run_switch_phase(model_fn, topic, verbose=False)
            item_switch_tokens = switch_tokens
            total_tokens += switch_tokens
            nano_tokens_total += switch_tokens
            total_switch_tokens += switch_tokens

            researcher_answers_list, thinker_results, rt_tokens = run_researcher_thinker_phase(
                model_fn, personas_data, topic, questions, verbose=False
            )
            item_rt_tokens = rt_tokens
            total_tokens += rt_tokens
            nano_tokens_total += rt_tokens
            total_rt_tokens += rt_tokens

            minimux_data, minimux_tokens = run_minimux_phase(
                mini_model_fn, topic, questions, researcher_answers_list, thinker_results, verbose=False
            )
            item_minimux_tokens = minimux_tokens
            total_tokens += minimux_tokens
            mini_tokens_total += minimux_tokens
            total_minimux_tokens += minimux_tokens

            # è¨ˆç®—æº–ç¢ºåº¦ï¼ˆä½¿ç”¨ Mini Mux çš„ final_answersï¼‰
            final_answers = minimux_data.get("final_answers", [])
            group_correct = 0
            for i, final_ans in enumerate(final_answers):
                if i >= len(correct_answers_list):
                    break

                final_norm = normalize_answer(final_ans)
                if not final_norm:
                    continue

                # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ­£ç¢ºç­”æ¡ˆ
                matched = False
                for correct_ans in correct_answers_list[i]:
                    correct_norm = normalize_answer(correct_ans)

                    # ç²¾ç¢º/åŒ…å«åŒ¹é…
                    if (
                        final_norm == correct_norm
                        or final_norm in correct_norm
                        or correct_norm in final_norm
                    ):
                        group_correct += 1
                        matched = True
                        break

                    # é—œéµè©åŒ¹é…ï¼ˆé•·åº¦>2çš„è©ï¼‰
                    final_words = [w for w in final_norm.split() if len(w) > 2]
                    correct_words = [w for w in correct_norm.split() if len(w) > 2]
                    if any(w in correct_norm for w in final_words) or any(w in final_norm for w in correct_words):
                        group_correct += 1
                        matched = True
                        break

                if not matched:
                    # æœªåŒ¹é…å‰‡ä¸åŠ åˆ†
                    pass

            item_group_correct = group_correct
            correct_count += group_correct
            total_questions += len(questions)
            
            # è¨˜éŒ„å„éšæ®µè¼¸å‡ºå…§å®¹
            item_researcher_output = researcher_answers_list
            item_thinker_output = [thinker_results[i]["analysis"] for i in sorted(thinker_results.keys())]
            item_minimux_answers = minimux_data.get("final_answers", [])
            item_minimux_story = minimux_data.get("final_story", "")

        except Exception as e:
            error_count += 1
            item_error_occurred = True
            item_error = str(e)
        
        # è¨˜éŒ„å–®é¡ŒçµæŸæ™‚é–“
        item_elapsed_time = time.time() - item_start_time
        total_elapsed_time += item_elapsed_time
        
        # ç«‹å³å¯«å…¥æ¯ä¸€é¡Œçš„çµæœåˆ° CSV
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        item_accuracy = (item_group_correct / len(questions) * 100) if questions else 0
        item_total_tokens = item_switch_tokens + item_rt_tokens + item_minimux_tokens
        
        # æº–å‚™å„éšæ®µè¼¸å‡ºå…§å®¹
        r_output = json.dumps(item_researcher_output, ensure_ascii=False, separators=(',', ':'))
        t_output = json.dumps(item_thinker_output, ensure_ascii=False, separators=(',', ':'))
        minimux_answers = json.dumps(item_minimux_answers, ensure_ascii=False, separators=(',', ':'))
        minimux_story = item_minimux_story
        
        with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp, topic, len(questions), item_group_correct, f"{item_accuracy:.1f}%",
                item_total_tokens, item_switch_tokens, item_rt_tokens, item_minimux_tokens, f"{item_elapsed_time:.2f}", "batch",
                r_output, t_output, minimux_answers, minimux_story
            ])

    # å®Œæˆé€²åº¦æ¢
    bar = "=" * 30
    final_accuracy = (correct_count / total_questions * 100) if total_questions > 0 else 0
    print(f"\ré€²åº¦: |{bar}| {total_groups}/{total_groups} (100.0%) | æº–ç¢ºåº¦: {final_accuracy:.1f}% | å®Œæˆ!{' '*20}")
    
    # æœ€çµ‚çµ±è¨ˆ
    print(f"\n{'='*60}")
    print("æ¸¬è©¦å®Œæˆï¼")
    print(f"ç¸½é¡Œçµ„: {total_groups} | æˆåŠŸ: {total_groups - error_count} | éŒ¯èª¤: {error_count}")
    print(f"ç¸½å•é¡Œæ•¸: {total_questions}")
    print(f"æ­£ç¢ºç­”æ¡ˆ: {correct_count}")
    print(f"æº–ç¢ºåº¦: {final_accuracy:.1f}%")
    print(f"ç¸½ Token: {total_tokens:,} | å¹³å‡/çµ„: {total_tokens/total_groups:.0f}")
    
    # æ™‚é–“çµ±è¨ˆ
    avg_time_per_group = total_elapsed_time / total_groups if total_groups > 0 else 0
    print(f"ç¸½åŸ·è¡Œæ™‚é–“: {total_elapsed_time:.2f}ç§’ ({total_elapsed_time/60:.2f}åˆ†é˜)")
    print(f"å¹³å‡/çµ„: {avg_time_per_group:.2f}ç§’ ({avg_time_per_group/60:.2f}åˆ†é˜)")
    
    # å¯«å…¥æ‰¹æ¬¡æ¸¬è©¦ç¸½é«”çµ±è¨ˆåˆ° CSV
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    total_time = total_elapsed_time
    
    with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([
            timestamp, f"æ‰¹æ¬¡æ¸¬è©¦({total_groups}çµ„)", total_questions, correct_count, f"{final_accuracy:.1f}%",
            total_tokens, total_switch_tokens, total_rt_tokens, total_minimux_tokens, f"{total_time:.2f}", "batch_summary",
            "", "", "", ""  # æ‰¹æ¬¡ç¸½çµ±è¨ˆä¸åŒ…å«å€‹åˆ¥è¼¸å‡ºå…§å®¹
        ])
    
    print(f"\nğŸ“Š è©³ç´°çµæœå·²å„²å­˜è‡³: {csv_path}")
    print(f"{'='*60}")


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    print("è«‹é¸æ“‡æ¸¬è©¦æ¨¡å¼:")
    print("1. single - å–®é¡Œæ¸¬è©¦")
    print("2. batch - æ‰¹æ¬¡æ¸¬è©¦ï¼ˆ100é¡Œï¼‰\n")

    mode = input("è«‹è¼¸å…¥ 'single' æˆ– 'batch': ").strip().lower()

    if mode == "batch":
        test_trivia_batch()
    elif mode == "single":
        test_trivia()
    else:
        print("ç„¡æ•ˆé¸é …ï¼ŒåŸ·è¡Œå–®é¡Œæ¸¬è©¦...")
        test_trivia()


if __name__ == "__main__":
    main()
